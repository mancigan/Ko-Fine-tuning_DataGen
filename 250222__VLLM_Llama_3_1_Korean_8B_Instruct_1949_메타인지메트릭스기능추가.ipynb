{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyPmVWV7Mq2VUO7WFiSHfLSe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "758558818aa44198b5ea1195f87f3fbc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fc018ed86da34a828de2b446b6e7b0a0",
              "IPY_MODEL_7e82e26b733541918ecd10597f3d3811",
              "IPY_MODEL_ecda71fe1b8f49ec83018c591351ca9b"
            ],
            "layout": "IPY_MODEL_ba8f1064179f421cb43fd8be7ce0c17b"
          }
        },
        "fc018ed86da34a828de2b446b6e7b0a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f60534bc0b4846c79bbd0f9f3e8edcd3",
            "placeholder": "​",
            "style": "IPY_MODEL_af03d5524d064ab690dd2214774fab7e",
            "value": ""
          }
        },
        "7e82e26b733541918ecd10597f3d3811": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3e73967ab4db42b09cc510edc4eb6167",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_67eae530e1a840fa9337d63ca16ec673",
            "value": 4
          }
        },
        "ecda71fe1b8f49ec83018c591351ca9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_229085a97a1f4c949b8653c1d6e9375d",
            "placeholder": "​",
            "style": "IPY_MODEL_7a6071d3f09940a580047761bf989c5b",
            "value": "Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:08&lt;00:00,  2.32s/it]\n"
          }
        },
        "ba8f1064179f421cb43fd8be7ce0c17b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f60534bc0b4846c79bbd0f9f3e8edcd3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af03d5524d064ab690dd2214774fab7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3e73967ab4db42b09cc510edc4eb6167": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "67eae530e1a840fa9337d63ca16ec673": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "229085a97a1f4c949b8653c1d6e9375d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a6071d3f09940a580047761bf989c5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mancigan/Ko-Fine-tuning_DataGen/blob/main/250222__VLLM_Llama_3_1_Korean_8B_Instruct_1949_%EB%A9%94%ED%83%80%EC%9D%B8%EC%A7%80%EB%A9%94%ED%8A%B8%EB%A6%AD%EC%8A%A4%EA%B8%B0%EB%8A%A5%EC%B6%94%EA%B0%80.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0hrlTac3MU_c",
        "outputId": "1129eda0-7ad5-41b7-e561-592504ea362a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Feb 21 23:49:12 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  NVIDIA A100-SXM4-40GB          Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   32C    P0             40W /  400W |       0MiB /  40960MiB |      0%      Default |\n",
            "|                                         |                        |             Disabled |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q vllm\n"
      ],
      "metadata": {
        "id": "9iH23JLiLmBI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09416719-d1e9-4f20-b425-1425f9b70e24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.6/264.6 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.5/96.5 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.6/71.6 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.0/111.0 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m81.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.6/87.6 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 MB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.7/16.7 MB\u001b[0m \u001b[31m89.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m396.9/396.9 kB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m114.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m87.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m55.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m95.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m343.3/343.3 kB\u001b[0m \u001b[31m32.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.8/94.8 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.2/44.2 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m113.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m70.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m376.2/376.2 kB\u001b[0m \u001b[31m37.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.7/210.7 kB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.9/43.9 MB\u001b[0m \u001b[31m50.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m912.7/912.7 kB\u001b[0m \u001b[31m56.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.4/119.4 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m243.3/243.3 kB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m112.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.6/313.6 kB\u001b[0m \u001b[31m32.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m35.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m97.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m452.6/452.6 kB\u001b[0m \u001b[31m33.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install vllm transformers pandas matplotlib --quiet\n"
      ],
      "metadata": {
        "id": "fjCx7DJ5Cai0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ 실행 예제 추가\n",
        "gen(\"인공지능이란 무엇인가?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kbqDO4IHNblK",
        "outputId": "8b6e0ece-6ace-4c91-de07-79a865e62e31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processed prompts: 100%|██████████| 1/1 [00:04<00:00,  4.81s/it, est. speed input: 20.38 toks/s, output: 65.09 toks/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "인공지능(AI)은 컴퓨터 시스템이 인간과 유사한 지능을 갖추어 문제를 해결하거나 학습하는 능력을 가리키는 용어입니다. 인공지능은 컴퓨터가 자동으로 데이터를 처리하고 분석하며, 이를 기반으로 결정을 내릴 수 있는 기술입니다. 인공지능은 여러 분야에서 응용되며, 예를 들면 자연어처리, 이미지 처리, 음성인식 등이 있습니다.\n",
            "\n",
            "인공지능의 종류에는 다음과 같은 것이 있습니다:\n",
            "\n",
            "1. **강화학습**: 환경에 대한 반응을 통해 학습하는 알고리즘\n",
            "2. **신경망**: 인간의 뇌와 유사한 구조로 구성된 알고리즘\n",
            "3. **심층신경망**: 다층 신경망으로 구성된 알고리즘\n",
            "\n",
            "인공지능은 다양한 분야에서 응용되며, 예를 들면 다음과 같습니다:\n",
            "\n",
            "1. **자연언어처리**: 컴퓨터가 자연 언어(말이나 글)를 이해하고 처리할 수 있는 기술\n",
            "2. **영상처理**: 컴퓨터가 영상 데이터를 분석하고 처리할 수 있는 기술\n",
            "3. **음성인식**: 컴퓨터가 음성을 이해하고 처리할 수 있는 기술\n",
            "\n",
            "총적으로 인공지능은 인간과 유사한 지성을 갖춘 컴퓨팅 시스템을 의미하며, 다양한 분야에서 응용되고 있습니다.\n",
            "\n",
            "혹시 더 자세히 궁금하신 점 있으시다면 알려주세요!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ 실행 예제 추가\n",
        "gen(\"인공지능이란?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hKH834CQnagp",
        "outputId": "f9efb2c7-c7d6-4d35-e145-6803c381e409"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processed prompts: 100%|██████████| 1/1 [00:04<00:00,  4.83s/it, est. speed input: 19.86 toks/s, output: 62.07 toks/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "인공지능은 컴퓨터 시스템이 인간의 지능을 모방하여 문제를 해결하거나 학습하는 기술입니다. 인공지능은 자연어 처리, 이미지 분석, 음성 인식 등 다양한 분야에서 응용됩니다. 인공지능은 두 가지 주요 유형으로 분류할 수 있습니다: 강화학습과 심층학습. 강화학습에서는 환경에 반응하여 행동을 수정하고 최적의 결과를 얻기 위해 학습합니다. 심층학련에서는 데이터로부터 패턴을 찾아내어 예측이나 분류와 같은 작업에 사용됩니다.\n",
            "\n",
            "예를 들어, 자율주행 자동차는 센서 데이터와 지도 정보를 기반으로 주변 환경을 분석하고 안전한 경로를 결정하는 것이 가능합니다. 또한 음성인식 기술로 컴퓨터가 사용자의 목소리를 이해하고 명령이나 질문에 답할 수 있습니다.\n",
            "\n",
            "하지만 인공지능도 몇 가지 제한점이 있으며, 그 중 하나는 데이터 양과 품질이 좋지 않으면 정확도가 떨어지는 것입니다. 또한 보안 문제도 존재하며, 악의적인 공격자가 시스템을 해킹하거나 개인정보 유출 등의 위험성이 있습니다.\n",
            "\n",
            "따라서 인공지능 개발자들은 이러한 문제들을 해결하기 위해 노력해야 하며, 사용자는 자신의 개인정보 보호 및 보안에 대한 중요성을 항상 기억해야 합니다.\n",
            "\n",
            "더 자세한 내용은 필요하시면 알려주세요!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "758558818aa44198b5ea1195f87f3fbc",
            "fc018ed86da34a828de2b446b6e7b0a0",
            "7e82e26b733541918ecd10597f3d3811",
            "ecda71fe1b8f49ec83018c591351ca9b",
            "ba8f1064179f421cb43fd8be7ce0c17b",
            "f60534bc0b4846c79bbd0f9f3e8edcd3",
            "af03d5524d064ab690dd2214774fab7e",
            "3e73967ab4db42b09cc510edc4eb6167",
            "67eae530e1a840fa9337d63ca16ec673",
            "229085a97a1f4c949b8653c1d6e9375d",
            "7a6071d3f09940a580047761bf989c5b"
          ]
        },
        "id": "MdMySVpWH36t",
        "outputId": "1097a924-a50c-4f8a-ed41-a99101bce3fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO 02-22 11:00:40 __init__.py:207] Automatically detected platform cuda.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING 02-22 11:00:42 config.py:2448] Casting torch.bfloat16 to torch.float16.\n",
            "INFO 02-22 11:00:53 config.py:549] This model supports multiple tasks: {'score', 'embed', 'generate', 'reward', 'classify'}. Defaulting to 'generate'.\n",
            "WARNING 02-22 11:00:53 arg_utils.py:1187] Chunked prefill is enabled by default for models with max_model_len > 32K. Currently, chunked prefill might not work with some features or models. If you encounter any issues, please disable chunked prefill by setting --enable-chunked-prefill=False.\n",
            "INFO 02-22 11:00:53 config.py:1555] Chunked prefill is enabled with max_num_batched_tokens=2048.\n",
            "INFO 02-22 11:00:53 llm_engine.py:234] Initializing a V0 LLM engine (v0.7.3) with config: model='sh2orc/Llama-3.1-Korean-8B-Instruct', speculative_config=None, tokenizer='sh2orc/Llama-3.1-Korean-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.float16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=sh2orc/Llama-3.1-Korean-8B-Instruct, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=False, chunked_prefill_enabled=True, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={\"splitting_ops\":[],\"compile_sizes\":[],\"cudagraph_capture_sizes\":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],\"max_capture_size\":256}, use_cached_outputs=False, \n",
            "INFO 02-22 11:00:55 cuda.py:229] Using Flash Attention backend.\n",
            "INFO 02-22 11:00:55 model_runner.py:1110] Starting to load model sh2orc/Llama-3.1-Korean-8B-Instruct...\n",
            "INFO 02-22 11:00:56 weight_utils.py:254] Using model weights format ['*.safetensors']\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]\n"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "758558818aa44198b5ea1195f87f3fbc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO 02-22 11:01:06 model_runner.py:1115] Loading model weights took 14.9888 GB\n",
            "INFO 02-22 11:01:07 worker.py:267] Memory profiling takes 0.82 seconds\n",
            "INFO 02-22 11:01:07 worker.py:267] the current vLLM instance can use total_gpu_memory (39.56GiB) x gpu_memory_utilization (0.90) = 35.60GiB\n",
            "INFO 02-22 11:01:07 worker.py:267] model weights take 14.99GiB; non_torch_memory takes 0.09GiB; PyTorch activation peak memory takes 1.19GiB; the rest of the memory reserved for KV Cache is 19.33GiB.\n",
            "INFO 02-22 11:01:07 executor_base.py:111] # cuda blocks: 9898, # CPU blocks: 2048\n",
            "INFO 02-22 11:01:07 executor_base.py:116] Maximum concurrency for 131072 tokens per request: 1.21x\n",
            "INFO 02-22 11:01:09 model_runner.py:1434] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Capturing CUDA graph shapes: 100%|██████████| 35/35 [00:24<00:00,  1.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO 02-22 11:01:34 model_runner.py:1562] Graph capturing finished in 25 secs, took 0.26 GiB\n",
            "INFO 02-22 11:01:34 llm_engine.py:436] init engine (profile, create kv cache, warmup model) took 28.43 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ 다단계 에이전트 기반 사분면 분석 시스템 실행 중...\n",
            "\n",
            "📌 분석할 영역을 선택하세요:\n",
            "1. 자기계발\n",
            "2. 다이어트\n",
            "3. 운동\n",
            "4. 학습\n",
            "5. 기타\n",
            "\n",
            "🔹 선택 (번호 입력): 2\n",
            "\n",
            "✅ 선택된 영역: 다이어트\n",
            "\n",
            "🔍 '다이어트' 영역의 행동을 탐색 중...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processed prompts: 100%|██████████| 1/1 [00:08<00:00,  8.04s/it, est. speed input: 17.05 toks/s, output: 65.08 toks/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📌 탐색된 행동 목록:\n",
            "['칼로리 계산', '식단 계획 수립', '식사량 조절', '가공식품 줄이기', '단백질 섭취 늘리기', '수분 섭취량 증가', '저녁 늦게 먹지 않기', '음식 기록하기', '배고플 때 과식 방지', '외식 메뉴 조절', '', \"2.'Keto' 다이어트 : 고지방/저탄수화물/저단백질 식사를 통해 에너지를 생성합니다\", '4. **건강 검진**: 정기적인 건강 검진으로 질병 예방 및 조기에 발견하는 방법들을 배우고 적용해 보세요.', '**기존 행위의 변형**', '3. **스트레스 관리**: 심리적 스트레스를 관리하고 줄이는 기술들을 배워서 다이어트 성공률 향상에 도움이 됩니다.', '**같은 의미지만 다른 표현**', '5. **생활 습관 개선**: 일상 생활에서 작은 변화부터 시작하여 더 큰 변화로 이끌어가는 방법들에 대해 학습하세요.', \"1.'다이어트' vs '건강관리': 두 용어는 동일하지만 '건강관리'는 더 광범위하게 이해됩니다\", '1. **식단 분석**: 식품의 영양소와 칼로리를 분석하여 개인 맞춤식 식단을 만들고, 건강 목표를 달성하는 데 도움을 받습니다.', \"1. '**Plant-Based' 다이어트:** 채소와 과일 등 채소 기반 식품 중심으로 구성된 식단입니다\", '3. **음료 선택 (Beverage Choice)**: 저칼로리 음료와 물 섭취를 늘리고 고칼로리 음료 섭취를 줄입니다.', '2. **운동 계획**: 운동 프로그램과 루틴을 설계하여 체중 감량과 근육 성장을 촉진하며, 건강한 생활 습관 형성을 지원합니다.', '다이어트 영역에서 수행할 수 있는 모든 행동을 나열하기 위해, 기존 데이터에 없는 새로운 행동을 우선적으로 탐색하고 기존 행동의 변형 또는 최신 트렌드를 반영한 변화를 탐색합니다. 또한, 같은 의미이지만 다르게 표현될 수 있는 행동이 있는지 확인합니다.', '**최신 트렌드 반영**', \"2.'체중감량' vs '체형개선': 두 용어 모두 같은 목표지만 차이가 있습니다\", '2. **간식 대체 (Snack Replacement)**: 간식을 대신하는 음식을 선택하거나 간식을 줄이는 방법들을 배워보세요.', '**새로운 hành위**', '1. **정통 다이어트 (Low-Carb)**: 탄수화물 섭취량 제한으로 체중 감량과 혈당 조절 효과가 있습니다.']\n",
            "\n",
            "🛠 기준 A (실천 여부)로 행동을 분류 중...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processed prompts: 100%|██████████| 1/1 [00:06<00:00,  6.79s/it, est. speed input: 102.64 toks/s, output: 64.80 toks/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📌 기준 A에 따른 분류 결과:\n",
            "안다/모른다로 구분한 결과는 다음과 같습니다:\n",
            "\n",
            "**안다:**\n",
            "\n",
            "1. 칼로리 계산\n",
            "2. 식단 계획 수립\n",
            "3. 식사량 조절\n",
            "4. 가공식품 줄이기\n",
            "5. 단백질 섭취 늘리기\n",
            "6. 수분 섭취량 증가\n",
            "7. 저녁 늦게 먹지 않기\n",
            "8. 음식 기록하기\n",
            "\n",
            "**모른다:**\n",
            "\n",
            "1.'체중감량' vs '체형개선': 두 용어 모두 같은 목표지만 차이가 있습니다.\n",
            "2.'Plant-Based' 다이어트: 채소와 과일 등 채소 기반 식품 중심으로 구성된 식단입니다.\n",
            "3.'Keto' 다이어트 : 고지방/저탄수화물/저단백질 식사를 통해 에너지를 생성합니다.\n",
            "4 '**건강 검진**: 정기적인 건강 검진으로 질병 예방 및 조기에 발견하는 방법들을 배우고 적용해 보세요.'\n",
            "5 '**스트레스 관리**: 심리적 스트레스를 관리하고 줄이는 기술들을 배워서 다이어트 성공률 향상에 도움이 됩니다.'\n",
            "6 '**생활 습관 개선**: 일상 생활에서 작은 변화부터 시작하여 더 큰 변화로 이끌어가는 방법들에 대해 학습하세요.'\n",
            "7 \"**음료 선택 (Beverage Choice)**: 저칼로리 음료와 물 섭취를 늘리고 고칼로리 음료 섭취를 줄입니다.\"\n",
            "8 \"**운동 계획**: 운동 프로그램과 루틴을 설계하여 체중 감량과 근육 성장을 촉진하며, 건강한 생활 습관 형성을 지원합니다.\"\n",
            "9 \"**간식 대체 (Snack Replacement)**: 간식을 대신하는 음식을 선택하거나 간식을 줄이는 방법들을 배워보세요.\"\n",
            "10 \"**정통 다이어트 (Low-Carb)**: 탄수화물 섭취량 제한으로 체중 감량과 혈당 조절 효과가 있습니다.\"\n",
            "\n",
            "🛠 기준 B (계획 여부)로 행동을 분류 중...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processed prompts: 100%|██████████| 1/1 [00:10<00:00, 10.64s/it, est. speed input: 65.82 toks/s, output: 64.98 toks/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📌 기준 B에 따른 분류 결과:\n",
            "할 수 있는 것과 할 수 없는 것을 구분하여 목록화합니다.\n",
            "\n",
            "**할 수 있는 것:**\n",
            "\n",
            "1. 칼로리 계산\n",
            "2. 식단 계획 수립\n",
            "3. 식사량 조절\n",
            "4. 가공식품 줄이기\n",
            "5. 단백질 섭취 늘리기\n",
            "6. 수분 섭취량 증가\n",
            "7. 저녁 늦게 먹지 않기\n",
            "8. 음식 기록하기\n",
            "9. 배고플 때 과식 방지\n",
            "\n",
            "**할 수 없는 것:**\n",
            "\n",
            "1.'체중감량' vs '체형개선'\n",
            "2.'Keto' 다이어트 : 고지방/저탄수화물/저단백질 식사를 통해 에너지를 생성합니다 (다이어트 영역에서 수행할 행동을 나열하는 목적에 부합하지 않습니다.)\n",
            "3.'Plant-Based' 다이어트: 채소와 과일 등 채소 기반 식품 중심으로 구성된 식단입니다 (다이어트 영역에서 수행할 행동을 나열하는 목적에 부합하지 않습니다.)\n",
            "4.'Low-Carb' 다이어트 : 탄수화물 섭취량 제한으로 체중 감량과 혈당 조절 효과가 있습니다 (다이어트 영역에서 수행할 행동을 나열하는 목적에 부합하지 않습니다.)\n",
            "\n",
            "위 목록은 데이터를 기준으로 분석했으며, 각 항목의 의미와 관련성을 고려하여 구분되었습니다.\n",
            "\n",
            "**추가 정보:**\n",
            "\n",
            "- **건강 검진**: 정기적인 건강 검진으로 질병 예방 및 조기에 발견하는 방법들을 배우고 적용해 보세요.\n",
            "- **스트레스 관리**: 심리적 스트레스를 관리하고 줄이는 기술들을 배워서 다이어트 성공률 향상에 도움이 됩니다.\n",
            "- **생활 습관 개선**: 일상 생활에서 작은 변화부터 시작하여 더 큰 변화로 이끌어가는 방법들에 대해 학습하세요.\n",
            "- **음료 선택 (Beverage Choice)**: 저칼로리 음료와 물 섭취를 늘리고 고칼로리 음료 섭취를 줄입니다.\n",
            "- **운동 계획**: 운동 프로그램과 루틴을 설계하여 체중 감량과 근육 성장을 촉진하며, 건강한 생활 습관 형성을 지원합니다.\n",
            "- '**간식 대체 (Snack Replacement)**': 간식을 대신하는 음식을 선택하거나 간식을 줄이는 방법들을 배워보세요.\n",
            "\n",
            "이러한 추가 정보는 각 항목의 의미와 관련성이 있으며, 데이터 분석 결과로부터 도출된 것입니다.\n",
            "\n",
            "또한, 다음과 같은 최신 트렌드 반영 및 새로운 행위도 존재합니다:\n",
            "\n",
            "* '**최신 트렌드 반영**'\n",
            "* '**새로운 행위**'\n",
            "\n",
            "이러한 최신 트렌드 반영 및 새로운 행위를 고려하면 더 많은 정보가 제공될 것입니다.\n",
            "\n",
            "마지막으로, 다음 항목은 동일하지만 다른 표현인 것으로 나타났습니다:\n",
            "\n",
            "* \"**같은 의미지만 다른 표현**\"\n",
            "\n",
            "따라서 이러한 항목들은 동일하게 처리될 것입니다.\n",
            "\n",
            "최종적으로 위 목록은 데이터 분석 결과로부터 도출되었으며, 각 항목의 의미와 관련성 등을 고려하였습니다\n",
            "\n",
            "🎯 목표 설정 중...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processed prompts: 100%|██████████| 1/1 [00:06<00:00,  6.58s/it, est. speed input: 11.55 toks/s, output: 65.50 toks/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🚀 설정된 목표:\n",
            "정해진 영역에서 최고수준을 탐색/설정하기 위해서는 다양한 데이터와 분석 방법이 필요합니다. 이에 대한 몇 가지 예시를 제공하겠습니다.\n",
            "\n",
            "1. **데이터 수집**: 정해진 영역의 데이터를 수집하고, 그 중에서 관련된 정보를 추출합니다. 예를 들어, 특정 지역의 기후 데이터나 인구 통계 등이 포함될 수 있습니다.\n",
            "2. **분석**: 추출한 데이터에 대해 분석을 수행하여 패턴이나 규칙을 찾습니다. 예를 들어, 특정 지역의 기후 변화나 인구 증가율 등이 포함될 수 있습니다.\n",
            "3. **목표 설정**: 분석 결과에 기반하여 목표 설정을 합니다. 예를 들어, 특정 지역의 환경 보전이나 경제 성장 등을 목표로 하여 계획과 정책을 세울 수도 있습니다.\n",
            "4. **최적화**: 목표 달성을 위해 최적화된 전략과 방법론을 개발합니다.\n",
            "\n",
            "예시:\n",
            "\n",
            "- **지역 개발 계획**:\n",
            "  - 대상: 도시 재개발\n",
            "  - 목표: 도시 재개발로 인한 주거 및 업무 공간 확보\n",
            "  - 분석: 도시 내부와 외부 교통망 개선 및 주거 공간 확보 방안 연구\n",
            "  - 최적화: 지속 가능한 개발 방향으로 조성하는 것\n",
            "\n",
            "- **환경 보전**:\n",
            "  - 대상: 자연 생태계 보호\n",
            "  - 목표: 자연 생태계 보호와 인간 활동 간 균형 유지\n",
            "  - 분석: 환경 영향 평가 및 생태계 건강도 조사 연구\n",
            "  - 최적화: 지속 가능한 에너지 사용과 자원 관리 방안\n",
            "\n",
            "- **교육 시스템 개선**:\n",
            "  - 대상: 교육 시스템 개선\n",
            "  - 목표: 교육 질 향상 및 학생 학습 능력 증대\n",
            "  - 분석 : 학생 성취도 평가 및 교육 과정 효율성 연구 \n",
            "   최적화 : 개인 맞춤형 학습 프로그램 도입\n",
            "\n",
            "✅ 분석 완료! 모든 결과가 출력되었습니다.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# 📌 Colab 실행용 코드: 사분면 분석 시스템\n",
        "\n",
        "# 1️⃣ 필수 라이브러리 설치 (Colab에서는 처음 실행 시 필요)\n",
        "!pip install vllm transformers pandas --quiet\n",
        "\n",
        "# 2️⃣ 라이브러리 불러오기\n",
        "from vllm import LLM, SamplingParams\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "import pandas as pd\n",
        "import torch  # ✅ NameError 방지를 위해 추가\n",
        "\n",
        "# 3️⃣ AI 모델 로드\n",
        "BASE_MODEL = \"sh2orc/Llama-3.1-Korean-8B-Instruct\"\n",
        "llm = LLM(model=BASE_MODEL, dtype=\"float16\")  # 📌 하나의 모델을 모든 에이전트가 공유\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "tokenizer.padding_side = 'right'\n",
        "\n",
        "# 4️⃣ AI 기반 텍스트 생성 함수\n",
        "def gen(instruction):\n",
        "    \"\"\"AI 모델을 활용하여 분석을 수행하는 함수\"\"\"\n",
        "    messages = [\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": \"당신은 AI 분석 에이전트입니다. 데이터를 기준으로 분석하고 목표를 설정하세요.\"\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": instruction\n",
        "        },\n",
        "    ]\n",
        "\n",
        "    prompt_message = tokenizer.apply_chat_template(\n",
        "        messages,\n",
        "        tokenize=False,\n",
        "        add_generation_prompt=True,\n",
        "    )\n",
        "\n",
        "    eos_token_id = [tokenizer.eos_token_id, tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")]\n",
        "\n",
        "    outputs = llm.generate(prompt_message, SamplingParams(\n",
        "        stop_token_ids=eos_token_id,\n",
        "        temperature=0.3,\n",
        "        top_p=0.9,\n",
        "        frequency_penalty=1.3,\n",
        "        max_tokens=4096))\n",
        "\n",
        "    return outputs[0].outputs[0].text\n",
        "\n",
        "\n",
        "# 📌 토큰 임베딩 모델 (VLLM은 임베딩 생성 불가능하므로 별도 모델 사용)\n",
        "EMBEDDING_MODEL = \"jhgan/ko-sbert-multitask\"\n",
        "embedding_tokenizer = AutoTokenizer.from_pretrained(EMBEDDING_MODEL)\n",
        "embedding_model = AutoModel.from_pretrained(EMBEDDING_MODEL)\n",
        "\n",
        "\n",
        "\n",
        "# 🔹 탐색된 데이터 저장용 DataFrame 생성\n",
        "exploration_data = pd.DataFrame(columns=[\"Domain\", \"Explored Actions\"])\n",
        "\n",
        "\n",
        "\n",
        "def clean_and_split_actions(actions):\n",
        "    \"\"\"불필요한 번호 제거 & 행동 데이터와 설명 데이터 분리\"\"\"\n",
        "\n",
        "    cleaned_actions = []\n",
        "    descriptions = {}\n",
        "\n",
        "    for action in actions:\n",
        "        # 1️⃣ 빈 값 제거\n",
        "        if not action.strip():\n",
        "            continue\n",
        "\n",
        "        # 2️⃣ 불필요한 메타데이터 제거\n",
        "        exclude_keywords = [\"기존 행위의 변형\", \"같은 의미지만 다른 표현\", \"최신 트렌드 반영\", \"새로운 hành위\"]\n",
        "        if any(keyword in action for keyword in exclude_keywords):\n",
        "            continue\n",
        "\n",
        "        # 3️⃣ \"VS\" 개념 제거 (비교 개념)\n",
        "        if \"vs\" in action.lower():\n",
        "            continue\n",
        "\n",
        "        # 4️⃣ 앞에 붙은 번호 제거 (예: \"1.\", \"2.\", \"3. **제목**: 설명\")\n",
        "        action = re.sub(r\"^\\d+\\.\\s*\", \"\", action).strip()\n",
        "\n",
        "        # 5️⃣ \"**제목**: 설명\" 형식의 데이터 분리\n",
        "        if \": \" in action:\n",
        "            title, desc = action.split(\": \", 1)\n",
        "            cleaned_actions.append(title.strip())  # 행동 데이터만 남김\n",
        "            descriptions[title.strip()] = desc.strip()  # 설명은 별도 저장\n",
        "        else:\n",
        "            cleaned_actions.append(action.strip())  # 설명이 없으면 그대로 저장\n",
        "\n",
        "    return list(set(cleaned_actions)), descriptions  # 중복 제거 후 반환\n",
        "\n",
        "\n",
        "def get_token_embeddings(text):\n",
        "    \"\"\"토큰 임베딩을 생성 (VLLM은 임베딩 불가 → Sentence Transformer 활용)\"\"\"\n",
        "    tokens = embedding_tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "    with torch.no_grad():\n",
        "        token_embeddings = embedding_model(**tokens).last_hidden_state\n",
        "    return token_embeddings.mean(dim=1).squeeze()  # 문장 임베딩 반환\n",
        "\n",
        "def cosine_similarity(vec1, vec2):\n",
        "    \"\"\"코사인 유사도 계산\"\"\"\n",
        "    return torch.nn.functional.cosine_similarity(vec1.unsqueeze(0), vec2.unsqueeze(0)).item()\n",
        "\n",
        "def detect_action_changes(existing_actions, generated_actions, threshold=0.8):\n",
        "    \"\"\"기존 행동과 의미가 유사하지만 표현이 다른 행동을 탐색 (VLLM 기반)\"\"\"\n",
        "    modified_actions = []\n",
        "    existing_embeddings = {action: get_token_embeddings(action) for action in existing_actions}\n",
        "\n",
        "    for action in generated_actions:\n",
        "        action_embedding = get_token_embeddings(action)\n",
        "        for existing_action, existing_embedding in existing_embeddings.items():\n",
        "            similarity = cosine_similarity(action_embedding, existing_embedding)\n",
        "            if similarity > threshold and action != existing_action:\n",
        "                modified_actions.append(action)\n",
        "                break  # 이미 유사한 행동이 발견되었으므로 추가 탐색 중단\n",
        "\n",
        "    return list(set(modified_actions))  # 중복 제거 후 반환\n",
        "\n",
        "\n",
        "# 🔹 기존 탐색된 데이터를 불러오는 함수\n",
        "def load_explored_actions(domain):\n",
        "    \"\"\"저장된 탐색된 행동 데이터를 불러옴\"\"\"\n",
        "    try:\n",
        "        df = pd.read_json(\"exploration_data.json\")\n",
        "        actions = df[df[\"Domain\"] == domain][\"Explored Actions\"].explode().tolist()\n",
        "        return actions if actions else []\n",
        "    except (FileNotFoundError, ValueError):\n",
        "        return []\n",
        "\n",
        "# 🔹 탐색된 데이터를 저장하는 함수\n",
        "def save_explored_actions(domain, actions, descriptions):\n",
        "    \"\"\"탐색된 행동 데이터를 축적하여 저장\"\"\"\n",
        "    global exploration_data\n",
        "\n",
        "    # 🔹 기존 데이터와 합쳐 중복 제거\n",
        "    unique_actions = list(set(actions))\n",
        "\n",
        "    # 🔹 DataFrame 업데이트\n",
        "    new_data = pd.DataFrame({\"Domain\": [domain], \"Explored Actions\": [unique_actions], \"Descriptions\": [descriptions]})\n",
        "    exploration_data = pd.concat([exploration_data, new_data], ignore_index=True)\n",
        "\n",
        "    # 🔹 데이터 저장 (파일로 축적)\n",
        "    exploration_data.to_json(\"exploration_data.json\", orient=\"records\", force_ascii=False)\n",
        "\n",
        "\n",
        "# 5️⃣ 탐색 에이전트 T (전체 행동 탐색)\n",
        "\n",
        "def explore_actions(domain):\n",
        "    \"\"\"탐색 에이전트: 특정 영역에서 수행할 수 있는 행동을 탐색\"\"\"\n",
        "\n",
        "    # 📌 1️⃣ 기본 제공 리스트 (사전 정의된 행동)\n",
        "    predefined_actions = {\n",
        "        \"다이어트\": [\n",
        "            \"칼로리 계산\", \"식단 계획 수립\", \"식사량 조절\", \"가공식품 줄이기\",\n",
        "            \"단백질 섭취 늘리기\", \"수분 섭취량 증가\", \"저녁 늦게 먹지 않기\",\n",
        "            \"음식 기록하기\", \"배고플 때 과식 방지\", \"외식 메뉴 조절\"\n",
        "        ]\n",
        "    }\n",
        "\n",
        "    # 📌 2️⃣ 사전 정의된 리스트 제공\n",
        "    actions = predefined_actions.get(domain, [])\n",
        "\n",
        "    # 📌 3️⃣ 기존 탐색된 행동 데이터 가져오기\n",
        "    existing_actions = load_explored_actions(\"다이어트\") or []\n",
        "\n",
        "    # 📌 4️⃣ AI 탐색 수행 (새로운 행동 & 기존 행동 변화 탐색)\n",
        "    instruction = f\"\"\"\n",
        "    '{domain}' 영역에서 수행할 수 있는 모든 행동을 나열하세요.\n",
        "    - 기존 데이터에 없는 새로운 행동을 우선적으로 탐색하세요.\n",
        "    - 기존 행동의 변형 또는 최신 트렌드를 반영한 변화를 탐색하세요.\n",
        "    - 같은 의미이지만 다르게 표현될 수 있는 행동이 있는지 확인하세요.\n",
        "    \"\"\"\n",
        "    generated_actions = gen(instruction)\n",
        "\n",
        "    # 🔹 4️⃣ AI 결과가 문자열이면 리스트로 변환\n",
        "    if isinstance(generated_actions, str):\n",
        "        generated_actions = generated_actions.split(\"\\n\")  # 줄바꿈 기준으로 리스트 변환\n",
        "\n",
        "    # 🔹 6️⃣ 기존 데이터와 비교하여 **새로운 행동만 필터링**\n",
        "    new_actions = list(set(generated_actions) - set(existing_actions))\n",
        "\n",
        "    # 🔹 7️⃣ 기존 행동의 변화나 새로운 트렌드 반영 여부 확인 (변화 탐색)\n",
        "    modified_actions = detect_action_changes(existing_actions, generated_actions)\n",
        "\n",
        "    # 📌 8️⃣ 불필요한 데이터 제거 및 설명 분리\n",
        "    cleaned_actions, action_descriptions = clean_and_split_actions(new_actions + modified_actions)\n",
        "\n",
        "    # 📌 9️⃣ 기존 리스트 + AI 탐색 결과 반환\n",
        "    all_actions = actions + cleaned_actions\n",
        "\n",
        "    # 🔹 10️⃣ 탐색된 데이터 저장 (중복 제거 후)\n",
        "    save_explored_actions(domain, all_actions, action_descriptions)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# 6️⃣ 기준 A를 분류하는 에이전트 A\n",
        "def classify_A(actions):\n",
        "    \"\"\" 안다/모른다\"\"\"\n",
        "    instruction = f\"안다/모른다로 구분하세요: {actions}\"\n",
        "    return gen(instruction)\n",
        "\n",
        "\n",
        "# 7️⃣ 기준 B를 분류하는 에이전트 B\n",
        "def classify_B(actions):\n",
        "    \"\"\"할수있다/할수없다.\"\"\"\n",
        "    instruction = f\"할수있다/할수없다로 구분하세요: {actions}\"\n",
        "    return gen(instruction)\n",
        "\n",
        "\n",
        "# 8️⃣ 목표 설정 에이전트 G\n",
        "def define_goal(actions_A, actions_B):\n",
        "    \"\"\"최고수준을 설정\"\"\"\n",
        "    instruction = f\"정해진 영역에서 최고수준을 탐색/설정하세요.\"\n",
        "    return gen(instruction)\n",
        "\n",
        "\n",
        "# 9️⃣ 사용자가 원하는 분석 영역 선택 기능\n",
        "def select_domain():\n",
        "    \"\"\"사용자가 원하는 분석 영역을 선택할 수 있도록 제공\"\"\"\n",
        "    available_domains = [\"자기계발\", \"다이어트\", \"운동\", \"학습\", \"기타\"]\n",
        "    print(\"\\n📌 분석할 영역을 선택하세요:\")\n",
        "    for idx, domain in enumerate(available_domains, 1):\n",
        "        print(f\"{idx}. {domain}\")\n",
        "\n",
        "    choice = int(input(\"\\n🔹 선택 (번호 입력): \"))\n",
        "\n",
        "    if choice == len(available_domains):  # \"기타\"를 선택하면 사용자 입력 받음\n",
        "        domain = input(\"\\n🔹 직접 입력하세요 (예: 업무 효율, 취미 개발 등): \")\n",
        "    else:\n",
        "        domain = available_domains[choice - 1]\n",
        "\n",
        "    print(f\"\\n✅ 선택된 영역: {domain}\")\n",
        "    return domain\n",
        "\n",
        "# 📌 Colab에서 `matplotlib` 실행 오류 방지\n",
        "%matplotlib inline\n",
        "\n",
        "\n",
        "# 9️⃣ 분석 결과를 매트릭스(사분면)에 배치하는 함수\n",
        "def plot_matrix(actions_A, actions_B):\n",
        "    \"\"\"기준 A, B를 기반으로 사분면(매트릭스) 그래프를 생성\"\"\"\n",
        "\n",
        "    # X축: 계획 여부 (B)\n",
        "    # Y축: 실천 여부 (A)\n",
        "    fig, ax = plt.subplots(figsize=(6, 6))\n",
        "\n",
        "    # 사분면 영역 설정\n",
        "    ax.set_xlim(-1, 1)\n",
        "    ax.set_ylim(-1, 1)\n",
        "\n",
        "    # 축 라벨 설정\n",
        "    ax.set_xlabel(\"계획 여부 (B)\")\n",
        "    ax.set_ylabel(\"실천 여부 (A)\")\n",
        "\n",
        "    # 중앙선 추가\n",
        "    ax.axhline(0, color='black', linewidth=1)\n",
        "    ax.axvline(0, color='black', linewidth=1)\n",
        "\n",
        "    # 사분면 제목 설정\n",
        "    ax.text(0.5, 0.8, \"1사분면\\n(실천 있음, 계획 있음)\", fontsize=12, ha='center')\n",
        "    ax.text(-0.5, 0.8, \"2사분면\\n(실천 있음, 계획 없음)\", fontsize=12, ha='center')\n",
        "    ax.text(-0.5, -0.8, \"3사분면\\n(실천 없음, 계획 없음)\", fontsize=12, ha='center')\n",
        "    ax.text(0.5, -0.8, \"4사분면\\n(실천 없음, 계획 있음)\", fontsize=12, ha='center')\n",
        "\n",
        "    # 사분면에 행동 배치\n",
        "    for action in actions_A.split(\", \"):\n",
        "        if action in actions_B:\n",
        "            ax.text(0.5, 0.5, action, fontsize=10, ha='center', color='blue')  # 1사분면\n",
        "        elif action not in actions_B:\n",
        "            ax.text(-0.5, 0.5, action, fontsize=10, ha='center', color='red')  # 2사분면\n",
        "\n",
        "    for action in actions_B.split(\", \"):\n",
        "        if action not in actions_A:\n",
        "            ax.text(0.5, -0.5, action, fontsize=10, ha='center', color='green')  # 4사분면\n",
        "        elif action not in actions_B:\n",
        "            ax.text(-0.5, -0.5, action, fontsize=10, ha='center', color='purple')  # 3사분면\n",
        "\n",
        "    plt.title(\"사분면 분석 매트릭스\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "\n",
        "# 🔟 Colab에서 실행할 메인 함수\n",
        "def main():\n",
        "    \"\"\"Colab에서 실행할 전체 분석 과정\"\"\"\n",
        "    print(\"✅ 다단계 에이전트 기반 사분면 분석 시스템 실행 중...\")\n",
        "\n",
        "    # 🔹 사용자 입력으로 분석할 영역 선택\n",
        "    domain = select_domain()\n",
        "\n",
        "    print(f\"\\n🔍 '{domain}' 영역의 행동을 탐색 중...\")\n",
        "    all_actions = explore_actions(domain)\n",
        "    print(f\"📌 탐색된 행동 목록:\\n{all_actions}\")\n",
        "\n",
        "    print(\"\\n🛠 기준 A (실천 여부)로 행동을 분류 중...\")\n",
        "    classified_A = classify_A(all_actions)\n",
        "    print(f\"📌 기준 A에 따른 분류 결과:\\n{classified_A}\")\n",
        "\n",
        "    print(\"\\n🛠 기준 B (계획 여부)로 행동을 분류 중...\")\n",
        "    classified_B = classify_B(all_actions)\n",
        "    print(f\"📌 기준 B에 따른 분류 결과:\\n{classified_B}\")\n",
        "\n",
        "    print(\"\\n🎯 목표 설정 중...\")\n",
        "    goal = define_goal(classified_A, classified_B)\n",
        "    print(f\"🚀 설정된 목표:\\n{goal}\")\n",
        "\n",
        "    print(\"\\n✅ 분석 완료! 모든 결과가 출력되었습니다.\")\n",
        "\n",
        "# 🔟 메인 실행\n",
        "main()\n"
      ]
    }
  ]
}